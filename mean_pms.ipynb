{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Mean Predictor Maps\n",
    "\n",
    "This Jupyter Notebook gives you the possiblity to calculate mean predictor maps for true positive and false negative predictions.\n",
    "\n",
    "Model Runs and stations need to be specified. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---\n",
    "# Modules\n",
    "#---\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "from data import data_loader\n",
    "from data import gesla_preprocessing\n",
    "from data import era5_preprocessing\n",
    "from data import preprocessing\n",
    "from data import saver\n",
    "from data import visualisation\n",
    "\n",
    "from models import modelfit\n",
    "from models import evaluation\n",
    "from models import loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_GESLA(station_names, season, detrend_type, percentile):\n",
    "    gesla_predictand = data_loader.load_gesla(station_names)\n",
    "    station_positions = gesla_preprocessing.station_position(gesla_predictand, station_names)\n",
    "    gesla_predictand = gesla_preprocessing.select_season(gesla_predictand, season)\n",
    "    gesla_predictand = gesla_preprocessing.get_analysis(gesla_predictand)\n",
    "    gesla_predictand = gesla_predictand[\"sea_level\"] # Select values\n",
    "    gesla_predictand = gesla_preprocessing.detrend_signal(gesla_predictand, type_=detrend_type) \n",
    "    gesla_predictand = gesla_preprocessing.apply_dummies(gesla_predictand, percentile=percentile, level=\"station\")\n",
    "    gesla_predictand = gesla_predictand.to_xarray()\n",
    "    \n",
    "    return gesla_predictand, station_positions\n",
    "\n",
    "def load_ERA5(range_of_years, subregion, season, predictor, preprocess=\"preprocess1\"):\n",
    "    era5_predictor = data_loader.load_daymean_era5(range_of_years, subregion, season, predictor, preprocess) \n",
    "    era5_predictor = preprocessing.convert_timestamp(era5_predictor, dim=\"time\")\n",
    "\n",
    "    # Convert predictor sp.unit from Pa to hPA\n",
    "    #---\n",
    "    if predictor == \"sp\":\n",
    "        with xr.set_options(keep_attrs=True):\n",
    "            old_unit = era5_predictor.attrs[\"units\"]\n",
    "            era5_predictor = era5_predictor / 100\n",
    "            era5_predictor.attrs[\"units\"] = \"hPa\"\n",
    "            new_unit = era5_predictor.attrs[\"units\"]\n",
    "            print(f\"Converted units of {predictor} from {old_unit} to {new_unit}\")\n",
    "\n",
    "    return era5_predictor\n",
    "\n",
    "def convert_data(X, Y,):\n",
    "\n",
    "            # Convert to format needed for model fit\n",
    "            #--- \n",
    "            n_pfs = 0\n",
    "\n",
    "            X = np.array(X)\n",
    "            Y = np.array(Y) \n",
    "            Y = Y[0, :] # Assume all timeseries are the same for the predictors.\n",
    "\n",
    "            # Reshape for model input\n",
    "            #---\n",
    "            print(f\"Reshape for model input\")\n",
    "\n",
    "            ndim = Y.shape[0]\n",
    "\n",
    "            X = X.swapaxes(0, 1) # Put time dimension to front\n",
    "\n",
    "            print(X.shape) # (time, timelags, predictor_combination, lon?, lat?)\n",
    "\n",
    "            X = X.reshape(ndim, -1) # Reshapes into (time, pred1_lonlats:pred2_lonlats:...:predn_lonlats)\n",
    "            y = Y[:, 0] # Select one station\n",
    "\n",
    "            #---\n",
    "            # Handle NaN Values\n",
    "            #---\n",
    "\n",
    "            # Insert numerical value that is not in data.\n",
    "            # ML will hopefully recognize it.\n",
    "            X[np.where(np.isnan(X))] = -999\n",
    "\n",
    "            print(\"Data is prepared as follows\")\n",
    "            print(f\"X.shape : {X.shape}\")\n",
    "            print(f\"y.shape : {y.shape}\")\n",
    "\n",
    "            return X, y\n",
    "\n",
    "#---\n",
    "def separate_predictors(importance, n_pred_features):\n",
    "    \"\"\"\n",
    "    Description: \n",
    "        Separates the importance of a single predictor from all features when multiple predictors were passed to the model\n",
    "    Parameters:\n",
    "        importance (np.array): Importance values of all features passed to model, Shape:(n_features,)\n",
    "        n_pred_features (int): number of features of a single predictor within all features\n",
    "    Returns:\n",
    "        predictor_importance (np.array): Importance of a single predictor from a model run, Shape:(n_predictors, n_pred_features)\n",
    "    Note: \n",
    "        From rf009 combinations of predictors and timelags are allowed. This function orders the n_pred_features as follows: \n",
    "        1: timelag1,pred1, 2:timelag1,pred2, ..., n: timelag1,pred_n, n+1: timelag2, pred1, ... t*n: timelag_t, pred_n\n",
    "        For an example see notebooks>rf009.ipynb\n",
    "    \"\"\"\n",
    "\n",
    "    # Separate importance of each predictor\n",
    "    predictor_importance = []\n",
    "    n_features = importance.shape[1]\n",
    "    n_predictors = n_features // n_pred_features\n",
    "\n",
    "    start = 0\n",
    "    for i in range(n_predictors):\n",
    "        end = start + n_pred_features \n",
    "        pred_importance = importance[:, start : end]\n",
    "        start = end # Update index for next predictor\n",
    "        \n",
    "        predictor_importance.append(pred_importance)\n",
    "\n",
    "    predictor_importance = np.array(predictor_importance, dtype=object) # If number of lon lats is not the same (can this happen?)\n",
    "\n",
    "    return predictor_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import loader\n",
    "#---\n",
    "# Initialize\n",
    "#---\n",
    "subregion = \"lon-0530_lat7040\" \n",
    "season = \"winter\"\n",
    "detrend_type = \"linear\"\n",
    "percentile = 0.95\n",
    "is_scaled = True\n",
    "model_run_flag = {\n",
    "    \"hanko-han-fin-cmems\" : \"FIN\", \n",
    "    \"forsmark-for-swe-cmems\" : \"WSWE\", \n",
    "    \"kalixstoron-kal-swe-cmems\" : \"NSWE\", \n",
    "    \"hamina-ham-fin-cmems\" : \"FINBAY\", \n",
    "    \"oskarshamn-osk-swe-cmems\" : \"WSWE2\",\n",
    "    \"daugavgriva-dau-lva-cmems\" : \"LVA\", \n",
    "    \"travemuende-tra-deu-cmems\" : \"DEU\",\n",
    "}\n",
    "range_of_years = \"1999-2008\"\n",
    "lats, lons = preprocessing.get_lonlats(\n",
    "    range_of_years=\"1999-2008\",\n",
    "    subregion=\"lon-0530_lat7040\",\n",
    "    season=\"winter\",\n",
    "    predictor=\"sp\", # Does not matter which predictor. All predictors are sampled on same lon-lat field.\n",
    "    era5_import=\"preprocess1\",\n",
    "    )\n",
    "\n",
    "n_pred_features = len(lons) * len(lats) \n",
    "nlevels = 10 # For contourplot of predictor maps\n",
    "\n",
    "colorbar_range = { # vmin vmax values for colorbar of predictor maps\n",
    "    'sp': np.array([ 980., 1020.,]),  # Low pressure systems <980hPa (see Theory Part)\n",
    "    'tp': np.array([0.    , 0.0018]),\n",
    "    'u10': np.array([-17.2,  17.2]), # Storm is defined by wind stronger than 17.2m/s\n",
    "    'v10': np.array([-17.2,  17.2]),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_run = \"rf022\"\n",
    "\n",
    "predictors_of_model = [ # Note!: If prefilling \"pf\" is used, they have to be always stated after ERA5 predictors\n",
    "\n",
    "    [\"sp\", \"tp\", \"u10\", \"v10\", \"pf\",],\n",
    "    [\"sp\", \"tp\", \"u10\", \"v10\", \"pf\",],\n",
    "\n",
    "]\n",
    "timelags_of_model = [ # Note!: If pf is used alone as a predictor, timelags need to be in hours instead of days\n",
    "    # [0, 2, 7], \n",
    "    # [7 * 24,]\n",
    "    #  \n",
    "    # [3, 7*24, 5*24, 2*24],\n",
    "\n",
    "    [1, 1, 1, 1, 1*24,],\n",
    "    [2, 2, 2, 2, 2*24,],\n",
    "]\n",
    "\n",
    "runids_of_model = [\n",
    "    0,\n",
    "    1,\n",
    "]\n",
    "station_names_of_model = [\n",
    "    [\"kalixstoron-kal-swe-cmems\",], #  NSWE\n",
    "    [\"hanko-han-fin-cmems\",], # FIN\n",
    "    [\"hamina-ham-fin-cmems\",], # FINBAY\n",
    "    [\"daugavgriva-dau-lva-cmems\",], # LVA\n",
    "    [\"travemuende-tra-deu-cmems\",], #  DEU\n",
    "    [\"oskarshamn-osk-swe-cmems\"], #  WSWE2 \n",
    "    [\"forsmark-for-swe-cmems\",], # WSWE\n",
    "]\n",
    "\n",
    "for station_names in station_names_of_model:\n",
    "    for idx, predictors in enumerate(predictors_of_model):\n",
    "        if all(x in [\"daugavgriva-dau-lva-cmems\", \"travemuende-tra-deu-cmems\"] for x in station_names): # Those stations only record from 2005-2020\n",
    "            range_of_years = \"2009-2018\"\n",
    "        else:\n",
    "            range_of_years = \"1999-2008\" # [\"1999-2008\", \"2009-2018\", \"2019-2022\",] \n",
    "        \n",
    "        is_pf_combined = preprocessing.check_combination(predictors)\n",
    "        X = []\n",
    "        Y = []\n",
    "        timelags = timelags_of_model[idx]\n",
    "        pred_units = {\n",
    "            \"sp\" : \"hPa\",\n",
    "            \"tp\" : \"m\",\n",
    "            \"u10\" : \"m/s\",\n",
    "            \"v10\" : \"m/s\",\n",
    "            \"pf\"  : \"m\"\n",
    "        }\n",
    "        cmap = {\n",
    "            \"sp\" : \"coolwarm\",\n",
    "            \"tp\"  : \"Blues\",\n",
    "            \"u10\" : \"seismic\",\n",
    "            \"v10\" : \"seismic\",\n",
    "        }\n",
    "        station_id = model_run_flag[station_names[0]]\n",
    "        model_path = f\"models/random_forest/{model_run}_{station_id}/{model_run}_{station_id}_RandomSearchCV_{runids_of_model[idx]}.sav\"\n",
    "        \n",
    "        gesla_predictand, station_positions = load_GESLA(station_names, season, detrend_type, percentile)\n",
    "        if is_pf_combined==True:\n",
    "            ts = preprocessing.intersect_all_times(predictors, gesla_predictand, range_of_years, subregion, season, preprocess=\"preprocess1\")\n",
    "        \n",
    "        era5_counter = 0\n",
    "        for pred_idx, predictor in enumerate(predictors):\n",
    "            #---\n",
    "            # Load Datasets of predictand and predictors\n",
    "            #---\n",
    "            if predictor == \"pf\":\n",
    "                is_prefilled = True\n",
    "\n",
    "                era5_predictor = data_loader.load_pf(season)\n",
    "\n",
    "                if is_pf_combined:\n",
    "                    X_ = preprocessing.get_timeseries(era5_predictor, ts, is_prefilling=True)\n",
    "                    Y_ = preprocessing.get_timeseries(gesla_predictand, ts, is_prefilling=True)\n",
    "                else:\n",
    "                    # If pf is used without any ERA5 data, use hourly data of Degerby.\n",
    "                    X_, Y_, t_ = preprocessing.intersect_time(era5_predictor, gesla_predictand, is_prefilled) \n",
    "\n",
    "            else: \n",
    "                is_prefilled = False\n",
    "                era5_counter = era5_counter + 1\n",
    "                era5_predictor = load_ERA5(range_of_years, subregion, season, predictor, preprocess=\"preprocess1\")\n",
    "                unit = pred_units[predictor] \n",
    "                if is_pf_combined:\n",
    "                    X_ = preprocessing.get_timeseries(era5_predictor, ts, is_prefilling=False)\n",
    "                    Y_ = preprocessing.get_timeseries(gesla_predictand, ts, is_prefilling=True)\n",
    "                else:\n",
    "                    X_, Y_, t_ = preprocessing.intersect_time(era5_predictor, gesla_predictand, is_prefilled)\n",
    "            #---\n",
    "            # Further preprocessing\n",
    "            #---\n",
    "\n",
    "            X_timelag, Y_timelag = preprocessing.add_timelag(X_, Y_, timelags, pred_idx) \n",
    "\n",
    "            X.append(X_timelag)\n",
    "            Y.append(Y_timelag)\n",
    "\n",
    "        if is_pf_combined:\n",
    "            Y = np.array(Y) \n",
    "            Y = Y[0, :] # Assume all timeseries are the same for the predictors.\n",
    "            ndim = Y.shape[0]\n",
    "            max_length = len(X)\n",
    "            n_pfs = max_length - era5_counter # Number of prefilling predictors\n",
    "\n",
    "            print(era5_counter, max_length, n_pfs, ndim)\n",
    "\n",
    "            era5_x = np.array(X[:era5_counter])\n",
    "            era5_x = era5_x.swapaxes(0, 1)\n",
    "            era5_x = era5_x.reshape(ndim, -1)\n",
    "\n",
    "            print(f\"ERA5 shape: {era5_x.shape}\")\n",
    "\n",
    "            #--- \n",
    "            # Insert prefilling data at the beginning\n",
    "            #---\n",
    "            XX = era5_x\n",
    "            for i in range(era5_counter, max_length):\n",
    "                XX = np.append(XX, X[i], axis=1)\n",
    "\n",
    "\n",
    "            y = Y[:, 0] # Select one station\n",
    "\n",
    "            #---\n",
    "            # Handle NaN Values\n",
    "            #---\n",
    "\n",
    "            # Insert numerical value that is not in data.\n",
    "            # ML will hopefully recognize it.\n",
    "            XX[np.where(np.isnan(XX))] = -999\n",
    "\n",
    "            X = XX\n",
    "            \n",
    "            del XX\n",
    "        else:\n",
    "            n_pfs = 0\n",
    "            X, y = convert_data(X, Y,)\n",
    "\n",
    "        #---\n",
    "        # Train Test split\n",
    "        #---\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0, test_size=0.25)\n",
    "\n",
    "        #---\n",
    "        # Scale data if they are on different scales\n",
    "        #---\n",
    "        X_test_unscaled = X_test\n",
    "\n",
    "        if is_scaled:\n",
    "            print(\"Scale training data\")\n",
    "            s = StandardScaler()\n",
    "            s.fit(X_train)\n",
    "            X_train = s.transform(X_train)\n",
    "            X_test = s.transform(X_test)\n",
    "\n",
    "        #---\n",
    "        # Make Prediction\n",
    "        #---\n",
    "        model = loader.load_model(model_path)\n",
    "        y_test_pred = model.predict(X_test)\n",
    "        \n",
    "        #---\n",
    "        # Get days of TPs, FPs, FNs\n",
    "        #---\n",
    "        # Filter TP (3), FN (2), FP(1), TN(0)\n",
    "        y_filtered = 2 * y_test + y_test_pred # Filter \n",
    "        tp_idx = np.where(y_filtered == 3)\n",
    "        fn_idx = np.where(y_filtered == 2)\n",
    "\n",
    "        if is_pf_combined:\n",
    "            X_test_unscaled_era5 = X_test_unscaled[:, :-n_pfs]\n",
    "            X_test_pred = separate_predictors(X_test_unscaled_era5, n_pred_features) # Plot only importance map of era5 data\n",
    "        else:\n",
    "            X_test_pred = separate_predictors(X_test_unscaled, n_pred_features)\n",
    "        X_test_tp = np.mean(X_test_pred[:, tp_idx[0], :], axis=1) # (4, 17061) e.g. (pred, nlat * nlon)\n",
    "        X_test_fn = np.mean(X_test_pred[:, fn_idx[0], :], axis=1)\n",
    "\n",
    "        for pred_idx, predictor in enumerate(predictors):            \n",
    "            # #---\n",
    "            # # Calculate mean of predictor maps\n",
    "            # #---\n",
    "            # X_test_tp = np.mean(X_test[tp_idx], axis=0)\n",
    "            # X_test_fn = np.mean(X_test[fn_idx], axis=0)\n",
    "\n",
    "            #---\n",
    "            # Plot figure\n",
    "            #---\n",
    "            if predictor in [\"sp\", \"tp\", \"u10\", \"v10\",]: # Filter if only certain predictors should be plotted [\"sp\", \"tp\", \"u10\", \"v10\"]\n",
    "                tlag = timelags[pred_idx]\n",
    "\n",
    "                data1 = X_test_fn[pred_idx, :] - X_test_tp[pred_idx, :]\n",
    "                data2 = X_test_tp[pred_idx, :]\n",
    "                data3 = X_test_fn[pred_idx, :]\n",
    "\n",
    "                vmin = min(data1)\n",
    "                vmax = max(data1)\n",
    "                tflag = f\"\"\"Difference of mean predictor maps \n",
    "                for {predictor} with timelag {tlag}\"\"\"\n",
    "\n",
    "                fig1, ax1 = visualisation.map(data1, lons, lats, tflag=tflag, unit=unit, vmin=vmin, vmax=vmax, nlevels=nlevels, cmap=cmap[predictor], pad=None)\n",
    "                \n",
    "                vmin, vmax = colorbar_range[predictor]\n",
    "                tflag = f\"\"\"Mean true positive predictor map\n",
    "                for {predictor} with timelag {tlag}\"\"\"\n",
    "\n",
    "                fig2, ax2 = visualisation.map(data2, lons, lats, tflag=tflag, unit=unit, vmin=vmin, vmax=vmax, nlevels=nlevels, cmap=cmap[predictor], pad=None)\n",
    "\n",
    "                vmin, vmax = colorbar_range[predictor]\n",
    "                tflag = f\"\"\"Mean false negative predictor map\n",
    "                for {predictor} with timelag {tlag}\"\"\"\n",
    "\n",
    "                fig3, ax3 = visualisation.map(data3, lons, lats, tflag=tflag, unit=unit, vmin=vmin, vmax=vmax, nlevels=nlevels, cmap=cmap[predictor], pad=None)\n",
    "                \n",
    "                # Add position of station to map\n",
    "                #---\n",
    "                for station_name in station_names:\n",
    "                    visualisation.plot_station(ax1, station_positions, station_name, is_station_name=False, is_legend=False)\n",
    "                    visualisation.plot_station(ax2, station_positions, station_name, is_station_name=False, is_legend=False)\n",
    "                    visualisation.plot_station(ax3, station_positions, station_name, is_station_name=False, is_legend=False)\n",
    "\n",
    "                # Add importance to map\n",
    "                #---\n",
    "                folder = f\"results/random_forest/{model_run}_{station_id}/\"\n",
    "                importance = np.load(f\"{folder}importance_95_{runids_of_model[idx]}.npy\")\n",
    "                era5_importance = importance[:-n_pfs]\n",
    "                predictor_importances = evaluation.separate_predictor_importance(era5_importance, n_pred_features)\n",
    "                pred_importance = predictor_importances[pred_idx]\n",
    "\n",
    "                evaluation.overlay_importance(ax1, pred_importance, lats, lons, percentile=99, alpha=0.08, markersize=5, color=\"k\")\n",
    "                evaluation.overlay_importance(ax2, pred_importance, lats, lons, percentile=99, alpha=0.08, markersize=5, color=\"k\")\n",
    "                evaluation.overlay_importance(ax3, pred_importance, lats, lons, percentile=99, alpha=0.08, markersize=5, color=\"k\")\n",
    "\n",
    "                # Save figure\n",
    "                #---\n",
    "                folder = f\"results/random_forest/{model_run}_{station_id}/\"\n",
    "                saver.directory_existance(folder)\n",
    "\n",
    "                fname1 = f\"meanmap_diff_{predictor}_tlag{tlag}_{runids_of_model[idx]}\"\n",
    "                fname2 = f\"meanmap_TP_{predictor}_tlag{tlag}_{runids_of_model[idx]}\"\n",
    "                fname3 = f\"meanmap_FN_{predictor}_tlag{tlag}_{runids_of_model[idx]}\"\n",
    "                \n",
    "                fig1.savefig(f\"{folder}{fname1}.pdf\")\n",
    "                print(f\"Saved Figure to {folder}{fname1}\")\n",
    "                fig2.savefig(f\"{folder}{fname2}.pdf\")\n",
    "                print(f\"Saved Figure to {folder}{fname2}\")\n",
    "                fig3.savefig(f\"{folder}{fname3}.pdf\")\n",
    "                print(f\"Saved Figure to {folder}{fname3}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('kivy')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "10d87a712a8ec9865a4f245f3c325b9f2014eacba896ac6957b582a55d9b22f2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
