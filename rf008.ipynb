{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description\n",
    "\n",
    "- Rerun rf004 with optimized Hyperparameter ranges and scaled (!) predictors\n",
    "- Use new savings of metrics, e.g. confusion matrix for train-set, relative accuracy etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next Steps\n",
    "\n",
    "- Modularize the hyperparameter and modelfit optimization, s.t. I can choose the classifier for each run and give a param grid to the run depending on the classifier (done)\n",
    "\n",
    "- Check if folders are there when creating it (done)\n",
    "\n",
    "- Check if GridSearchCV or RandomSearchCV need StandardScaler() as argument to scale the training data! Very important! Maybe I need to use Pipelines for this and implement the Pipeline in the fitting module. (I scaled the data beforehand, that should be sufficient). (done)\n",
    "\n",
    "- implement this: use_params (dict): Dictionary of hyperparameters that should be used for model. If None, hyperparameters are optimized. (Defaults: None). done\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working Area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Predictand from GESLA\n",
      "Applied one-hot-encoding with Percentile: 0.95\n",
      "Add predictor sp to model input features\n",
      "Get overlapping timeseries of ERA5 and GESLA\n",
      "Add predictor u10 to model input features\n",
      "Get overlapping timeseries of ERA5 and GESLA\n",
      "Assert that timeinterval of all predictors are the same\n",
      "Time-interval is the same\n",
      "Time-interval is the same\n",
      "All Time-intervals are the same\n",
      "Prepare input data for model training\n",
      "Data is prepared as follows\n",
      "X.shape : (903, 34122)\n",
      "y.shape : (903,)\n",
      "Start Model Training\n",
      "Do Train-Test-Split\n",
      "Scale training data\n",
      "Optimize Hyperparameters using RandomSearchCV\n",
      "Tested Hyperparameters: {'n_estimators': [0, 111, 222, 333, 444, 555, 666, 777, 888, 1000], 'max_depth': [5, 17, 30, 42, 55, None], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4], 'criterion': ['gini'], 'random_state': [0], 'class_weight': ['balanced'], 'oob_score': [True]}\n",
      "Optimize Hyperparameters using RandomSearchCV\n",
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\OneDrive\\Alle_Ordner\\Coding\\Python\\master_thesis\\rf008.ipynb Zelle 4\u001b[0m in \u001b[0;36m<cell line: 53>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/OneDrive/Alle_Ordner/Coding/Python/master_thesis/rf008.ipynb#ch0000014?line=42'>43</a>\u001b[0m hparam_grid \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mn_estimators\u001b[39m\u001b[39m'\u001b[39m: n_estimators, \u001b[39m# hparam grid if optimization is needed\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/OneDrive/Alle_Ordner/Coding/Python/master_thesis/rf008.ipynb#ch0000014?line=43'>44</a>\u001b[0m             \u001b[39m'\u001b[39m\u001b[39mmax_depth\u001b[39m\u001b[39m'\u001b[39m: max_depth,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/OneDrive/Alle_Ordner/Coding/Python/master_thesis/rf008.ipynb#ch0000014?line=44'>45</a>\u001b[0m             \u001b[39m'\u001b[39m\u001b[39mmin_samples_split\u001b[39m\u001b[39m'\u001b[39m: min_samples_split,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/OneDrive/Alle_Ordner/Coding/Python/master_thesis/rf008.ipynb#ch0000014?line=49'>50</a>\u001b[0m             \u001b[39m'\u001b[39m\u001b[39moob_score\u001b[39m\u001b[39m'\u001b[39m : [\u001b[39mTrue\u001b[39;00m,],\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/OneDrive/Alle_Ordner/Coding/Python/master_thesis/rf008.ipynb#ch0000014?line=50'>51</a>\u001b[0m             }\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/OneDrive/Alle_Ordner/Coding/Python/master_thesis/rf008.ipynb#ch0000014?line=52'>53</a>\u001b[0m \u001b[39mfor\u001b[39;00m run_id, predictors \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(preds):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/OneDrive/Alle_Ordner/Coding/Python/master_thesis/rf008.ipynb#ch0000014?line=53'>54</a>\u001b[0m     rf008\u001b[39m.\u001b[39;49mrun(season, predictors, percentile, station_names, \n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/OneDrive/Alle_Ordner/Coding/Python/master_thesis/rf008.ipynb#ch0000014?line=54'>55</a>\u001b[0m     clf, hparam_grid, optimizer, \n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/OneDrive/Alle_Ordner/Coding/Python/master_thesis/rf008.ipynb#ch0000014?line=55'>56</a>\u001b[0m     run_id, model_run, \n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/OneDrive/Alle_Ordner/Coding/Python/master_thesis/rf008.ipynb#ch0000014?line=56'>57</a>\u001b[0m     k, n_iter, is_optimized\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, is_scaled\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[1;32md:\\OneDrive\\Alle_Ordner\\Coding\\Python\\master_thesis\\models\\random_forest\\rf008.py:188\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(season, predictors, percentile, station_names, clf, hparam_grid, optimizer, run_id, model_run, k, n_iter, is_optimized, is_scaled)\u001b[0m\n\u001b[0;32m    186\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mOptimize Hyperparameters using \u001b[39m\u001b[39m{\u001b[39;00moptimizer\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    187\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTested Hyperparameters: \u001b[39m\u001b[39m{\u001b[39;00mhparam_grid\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 188\u001b[0m     hparam_grid \u001b[39m=\u001b[39m modelfit\u001b[39m.\u001b[39;49moptimize_hyperparameter(X_train, y_train, clf(), optimizer, hparam_grid, k, n_iter, n_jobs\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[0;32m    190\u001b[0m \u001b[39m#---\u001b[39;00m\n\u001b[0;32m    191\u001b[0m \u001b[39m#  Save hyperparameters\u001b[39;00m\n\u001b[0;32m    192\u001b[0m \u001b[39m#---\u001b[39;00m\n\u001b[0;32m    193\u001b[0m folder \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmodels/random_forest/\u001b[39m\u001b[39m{\u001b[39;00mmodel_run\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m\"\u001b[39m \n",
      "File \u001b[1;32md:\\OneDrive\\Alle_Ordner\\Coding\\Python\\master_thesis\\models\\modelfit.py:49\u001b[0m, in \u001b[0;36moptimize_hyperparameter\u001b[1;34m(X_train, y_train, clf, optimizer, param_grid, k, n_iter, n_jobs)\u001b[0m\n\u001b[0;32m     41\u001b[0m     opt_model \u001b[39m=\u001b[39m GridSearchCV(estimator\u001b[39m=\u001b[39mclf, \n\u001b[0;32m     42\u001b[0m     param_grid \u001b[39m=\u001b[39m param_grid, \n\u001b[0;32m     43\u001b[0m     cv \u001b[39m=\u001b[39m k,\n\u001b[0;32m     44\u001b[0m     verbose \u001b[39m=\u001b[39m \u001b[39m2\u001b[39m, \n\u001b[0;32m     45\u001b[0m     n_jobs \u001b[39m=\u001b[39m n_jobs, \n\u001b[0;32m     46\u001b[0m     )\n\u001b[0;32m     48\u001b[0m \u001b[39m# Fit the random search model\u001b[39;00m\n\u001b[1;32m---> 49\u001b[0m opt_model\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[0;32m     51\u001b[0m \u001b[39m# Best Params\u001b[39;00m\n\u001b[0;32m     52\u001b[0m \u001b[39m#---\u001b[39;00m\n\u001b[0;32m     54\u001b[0m \u001b[39mreturn\u001b[39;00m opt_model\u001b[39m.\u001b[39mbest_params_\n",
      "File \u001b[1;32md:\\Programme\\miniconda3\\envs\\mlpy38\\lib\\site-packages\\sklearn\\model_selection\\_search.py:891\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    885\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[0;32m    886\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    887\u001b[0m     )\n\u001b[0;32m    889\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[1;32m--> 891\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[0;32m    893\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    894\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    895\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32md:\\Programme\\miniconda3\\envs\\mlpy38\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1766\u001b[0m, in \u001b[0;36mRandomizedSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1764\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1765\u001b[0m     \u001b[39m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1766\u001b[0m     evaluate_candidates(\n\u001b[0;32m   1767\u001b[0m         ParameterSampler(\n\u001b[0;32m   1768\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_distributions, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_iter, random_state\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrandom_state\n\u001b[0;32m   1769\u001b[0m         )\n\u001b[0;32m   1770\u001b[0m     )\n",
      "File \u001b[1;32md:\\Programme\\miniconda3\\envs\\mlpy38\\lib\\site-packages\\sklearn\\model_selection\\_search.py:838\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    830\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    831\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[0;32m    832\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    833\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m    834\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[0;32m    835\u001b[0m         )\n\u001b[0;32m    836\u001b[0m     )\n\u001b[1;32m--> 838\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[0;32m    839\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    840\u001b[0m         clone(base_estimator),\n\u001b[0;32m    841\u001b[0m         X,\n\u001b[0;32m    842\u001b[0m         y,\n\u001b[0;32m    843\u001b[0m         train\u001b[39m=\u001b[39;49mtrain,\n\u001b[0;32m    844\u001b[0m         test\u001b[39m=\u001b[39;49mtest,\n\u001b[0;32m    845\u001b[0m         parameters\u001b[39m=\u001b[39;49mparameters,\n\u001b[0;32m    846\u001b[0m         split_progress\u001b[39m=\u001b[39;49m(split_idx, n_splits),\n\u001b[0;32m    847\u001b[0m         candidate_progress\u001b[39m=\u001b[39;49m(cand_idx, n_candidates),\n\u001b[0;32m    848\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs,\n\u001b[0;32m    849\u001b[0m     )\n\u001b[0;32m    850\u001b[0m     \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n\u001b[0;32m    851\u001b[0m         \u001b[39menumerate\u001b[39;49m(candidate_params), \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, groups))\n\u001b[0;32m    852\u001b[0m     )\n\u001b[0;32m    853\u001b[0m )\n\u001b[0;32m    855\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    856\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    857\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    858\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    859\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    860\u001b[0m     )\n",
      "File \u001b[1;32md:\\Programme\\miniconda3\\envs\\mlpy38\\lib\\site-packages\\joblib\\parallel.py:1056\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1053\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m   1055\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1056\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mretrieve()\n\u001b[0;32m   1057\u001b[0m \u001b[39m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[0;32m   1058\u001b[0m elapsed_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_start_time\n",
      "File \u001b[1;32md:\\Programme\\miniconda3\\envs\\mlpy38\\lib\\site-packages\\joblib\\parallel.py:935\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    933\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    934\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, \u001b[39m'\u001b[39m\u001b[39msupports_timeout\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m--> 935\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout))\n\u001b[0;32m    936\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    937\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39mget())\n",
      "File \u001b[1;32md:\\Programme\\miniconda3\\envs\\mlpy38\\lib\\site-packages\\joblib\\_parallel_backends.py:542\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    539\u001b[0m \u001b[39m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[0;32m    540\u001b[0m \u001b[39mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[0;32m    541\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 542\u001b[0m     \u001b[39mreturn\u001b[39;00m future\u001b[39m.\u001b[39;49mresult(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[0;32m    543\u001b[0m \u001b[39mexcept\u001b[39;00m CfTimeoutError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    544\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[1;32md:\\Programme\\miniconda3\\envs\\mlpy38\\lib\\concurrent\\futures\\_base.py:439\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    436\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[0;32m    437\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__get_result()\n\u001b[1;32m--> 439\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_condition\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[0;32m    441\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[0;32m    442\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[1;32md:\\Programme\\miniconda3\\envs\\mlpy38\\lib\\threading.py:302\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    300\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[0;32m    301\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 302\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[0;32m    303\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    304\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#---\n",
    "# Initialize\n",
    "#---\n",
    "from models.random_forest import rf008\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "\n",
    "model_run = \"rf008\"\n",
    "season = \"winter\" # [\"winter\", \"autumn\",] \n",
    "percentile = 0.95 # [0.95, 0.99,] \n",
    "station_names = [\"hanko-han-fin-cmems\",]\n",
    "preds = [\n",
    "    [\"sp\", \"u10\",], # run_id 0\n",
    "    [\"sp\", \"tp\", \"u10\",], # run_id 1,...\n",
    "    [\"sp\", \"tp\",],\n",
    "    [\"tp\",\"u10\"],\n",
    "    [\"sp\", \"tp\", \"u10\", \"v10\"],\n",
    "]\n",
    "\n",
    "clf = RandomForestClassifier\n",
    "optimizer = \"RandomSearchCV\" #[\"RandomSearchCV\", \"GridSearchCV\"]\n",
    "n_iter = 100 \n",
    "k = 3\n",
    "#---\n",
    "# Build Hyperparameter Grid to optimize from.\n",
    "# For this run, use exactly the same as in rf004 to see if \n",
    "# scaling of predictor data leads to any changes.\n",
    "#---\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 0, stop = 1000, num = 10)]\n",
    "\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(5, 55, num = 5)]\n",
    "max_depth.append(None)\n",
    "\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "\n",
    "# Create the random grid\n",
    "hparam_grid = {'n_estimators': n_estimators, # hparam grid if optimization is needed\n",
    "            'max_depth': max_depth,\n",
    "            'min_samples_split': min_samples_split,\n",
    "            'min_samples_leaf': min_samples_leaf,\n",
    "            'criterion' : ['gini',],\n",
    "            'random_state' : [0,], # To compare results when changing hyperparameters\n",
    "            'class_weight' : [\"balanced\",],\n",
    "            'oob_score' : [True,],\n",
    "            }\n",
    "\n",
    "for run_id, predictors in enumerate(preds):\n",
    "    rf008.run(season, predictors, percentile, station_names, \n",
    "    clf, hparam_grid, optimizer, \n",
    "    run_id, model_run, \n",
    "    k, n_iter, is_optimized=True, is_scaled=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used model: RandomForestClassifier(class_weight='balanced', criterion='entropy',\n",
      "                       max_depth=4, min_samples_leaf=2, n_estimators=1,\n",
      "                       oob_score=True, random_state=0)\n",
      "Fit model\n",
      "Testscore: 0.9333333333333333\n",
      "Trainscore: 0.9459459459459459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Programme\\miniconda3\\envs\\mlpy38\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:560: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "#---\n",
    "# Goal: Check if clf = classifier of my choice is adjustable or not like \n",
    "# model = clf(param_grid)\n",
    "# Use best_params from modelfit.optimize_hyperparameter output to apply params to model.\n",
    "#---\n",
    "\n",
    "#---\n",
    "# Load example data \n",
    "#---\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "with zipfile.ZipFile('../courses/machine_learning/Kursmaterialien.zip', 'r') as source:\n",
    "    with source.open('Kursmaterialien/Abschnitt 26 - Entscheidungsbaeume/classification.csv') as file:\n",
    "        df = pd.read_csv(file, low_memory=False)\n",
    "\n",
    "df.head()\n",
    "\n",
    "#- Train & Test split\n",
    "X = df.drop('success', axis = 1).values #- Copies DF\n",
    "y = df['success'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0, test_size=0.25)\n",
    "\n",
    "# Example parameters for model fit\n",
    "#---\n",
    "clf = RandomForestClassifier\n",
    "best_params = {\n",
    "    \"n_estimators\" : 1,\n",
    "    \"max_depth\" : 4, \n",
    "    \"criterion\" : \"entropy\",\n",
    "    \"min_samples_leaf\" : 2, \n",
    "    \"min_samples_split\" : 2, \n",
    "    \"random_state\" : 0, \n",
    "    \"class_weight\" : \"balanced\",\n",
    "    \"oob_score\" : True,\n",
    "}\n",
    "\n",
    "#---\n",
    "# Fit the model\n",
    "#---\n",
    "model1 = clf(**best_params) # One can set parameters afterwards via model.set_params()\n",
    "\n",
    "model2 = RandomForestClassifier(criterion='gini',\n",
    "n_estimators=best_params[\"n_estimators\"], #- nTrees \n",
    "max_depth=best_params[\"max_depth\"], \n",
    "min_samples_leaf=best_params[\"min_samples_leaf\"],\n",
    "min_samples_split=best_params[\"min_samples_split\"],\n",
    "random_state=0, # To compare results when changing hyperparameters\n",
    "class_weight=\"balanced\",\n",
    "oob_score=True,\n",
    ") \n",
    "\n",
    "print(f\"Used model: {model1}\")\n",
    "print(\"Fit model\")\n",
    "model1.fit(X_train, y_train)\n",
    "print(f\"Testscore: {model1.score(X_test, y_test)}\")\n",
    "print(f\"Trainscore: {model1.score(X_train, y_train)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mSignature:\u001b[0m\n",
      "\u001b[0mmodelfit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimize_hyperparameter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mclf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mparam_grid\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mn_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mDocstring:\u001b[0m\n",
      "Description: \n",
      "    Return best hyperparameters for a model based on chosen optimizer\n",
      "Parameters:\n",
      "    X_train (): Predictor train data\n",
      "    y_train (): Predictand train data\n",
      "    clf (): Base Model\n",
      "    optimizer (): GridSearchCV or RandomizedSearchCV\n",
      "    param_grid (dict): Dictionary with hyperparameter ranges\n",
      "    k (int): k-fold Cross-Validation\n",
      "    n_iter (int): Number of combinations used for RandomizedSearchCV (Defaults:None)\n",
      "    n_jobs (int): Number of processor used. (Defaults:-1, e.g. all processors)\n",
      "\u001b[1;31mFile:\u001b[0m      d:\\onedrive\\alle_ordner\\coding\\python\\master_thesis\\models\\modelfit.py\n",
      "\u001b[1;31mType:\u001b[0m      function\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from models import modelfit\n",
    "\n",
    "type(LogisticRegression())\n",
    "modelfit.optimize_hyperparameter?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---\n",
    "# Scale data\n",
    "#---\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "s = StandardScaler()\n",
    "s.fit(X_train)\n",
    "X_train = s.transform(X_train)\n",
    "X_test = s.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---\n",
    "# Learning Curve\n",
    "#---\n",
    "\n",
    "#- Train & Test split\n",
    "X = df.drop('success', axis = 1).values #- Copies DF\n",
    "y = df['success'].values\n",
    "\n",
    "#- Plot Learning Curve\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.utils import shuffle\n",
    "import numpy as np\n",
    "\n",
    "X, y = shuffle(X, y) #- random selection of data. Good if you dont know if data is ordered\n",
    "train_sizes_abs, train_scores, test_scores = learning_curve(LogisticRegression(), X, y)\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(train_sizes_abs, np.mean(train_scores, axis = 1)) #- learning curve macht automatisch k-fold crossvalidation. deswegen mean\n",
    "plt.plot(train_sizes_abs, np.mean(test_scores, axis = 1)) #- learning curve macht automatisch k-fold crossvalidation. deswegen mean\n",
    "\n",
    "plt.show()\n",
    "\n",
    "#- Note: Do this more often to get mean. Sometimes Curves look weird."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---\n",
    "# Pipeline GridSearchCV: \n",
    "# Add this to modelfit.py?\n",
    "#---\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC \n",
    "\n",
    "pipeline = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"svc\", SVC()),\n",
    "])\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "clf = GridSearchCV(pipeline, param_grid = {\n",
    "    \"svc__C\": [0.001, 0.01, 0.1, 1, 10,],\n",
    "    \"svc__gamma\": [0.001, 0.01, 0.1, 1, 10,],\n",
    "})\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(clf.best_params_)\n",
    "\n",
    "print(clf.score(X_validation, y_validation)) # Accuracy on basis of test data\n",
    "\n",
    "print(clf.best_score_) # Accuracy based on k-fold cross-validation"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "dbda0df39e8d9f08c77def502e386bb54b10e33e74098d5a47640c70cb49662a"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('mlpy38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
